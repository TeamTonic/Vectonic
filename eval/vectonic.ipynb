{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcome to the Vectonic Evaluation !\n",
    "\n",
    "here, we're evaluating the various configurations of the `Unstructured.io` `Vectara-Cli` and `Together.ai` pipeline using `tonicai` to see how the available enhancements improve retrieval. Although we're using the vectara-cli these advanced RAG techniques are transferable to other models and other techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules have been successfully imported and are ready for use.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Function to handle package installations\n",
    "def install(packages):\n",
    "    for package in packages.split():\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Preemptively install essential packages\n",
    "install(\"spacy ipywidgets\")\n",
    "\n",
    "# Install vector retrieval and evaluation frameworks\n",
    "packages = \"tonic-validate vectara-cli vectara-cli[rebel_span] llama-index-core llama-index-readers-file \" \\\n",
    "           \"llama-index-llms-together llama-parse python-magic-bin==0.4.14\"\n",
    "install(packages)\n",
    "\n",
    "# Function to safely attempt imports and install if packages are missing\n",
    "def try_import(module_name, from_list):\n",
    "    try:\n",
    "        module = __import__(module_name, fromlist=from_list)\n",
    "        return module\n",
    "    except ImportError:\n",
    "        install(module_name)\n",
    "        module = __import__(module_name, fromlist=from_list)\n",
    "        return module\n",
    "\n",
    "# Importing and initializing Vectara CLI modules safely\n",
    "vectara_cli = try_import(\"vectara_cli\", [\"core\", \"rebel_span.noncommercial.nerdspan\", \"rebel_span.commercial.enterprise\"])\n",
    "VectaraClient = getattr(vectara_cli.core, \"VectaraClient\")\n",
    "Span = getattr(vectara_cli.rebel_span.noncommercial.nerdspan, \"Span\")\n",
    "EnterpriseSpan = getattr(vectara_cli.rebel_span.commercial.enterprise, \"EnterpriseSpan\")\n",
    "\n",
    "try:\n",
    "    import llama_index\n",
    "    from llama_index.core import SimpleDirectoryReader\n",
    "    from llama_index.readers.file import UnstructuredReader\n",
    "    from llama_index.llms.together import TogetherLLM\n",
    "except ImportError:\n",
    "    install(\"llama-index-core\")\n",
    "    install(\"llama-index-readers-file\")\n",
    "    install(\"llama-index-llms-together\")\n",
    "    from llama_index.core import SimpleDirectoryReader\n",
    "    from llama_index.readers.file import UnstructuredReader\n",
    "    from llama_index.llms.together import TogetherLLM\n",
    "# Importing validation and benchmarking tools from tonic-validate\n",
    "tonic_validate = try_import(\"tonic_validate\", [\"ValidateScorer\", \"Benchmark\"])\n",
    "ValidateScorer = getattr(tonic_validate, \"ValidateScorer\")\n",
    "Benchmark = getattr(tonic_validate, \"Benchmark\")\n",
    "\n",
    "# Note to check if all modules are imported correctly\n",
    "print(\"All modules have been successfully imported and are ready for use.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 15:44:27,133 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2024-04-18 15:44:27,144 - DEBUG - load_verify_locations cafile='C:\\\\Users\\\\MeMyself\\\\AppData\\\\Roaming\\\\Python\\\\Python312\\\\site-packages\\\\certifi\\\\cacert.pem'\n",
      "2024-04-18 15:44:27,171 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2024-04-18 15:44:27,173 - DEBUG - load_verify_locations cafile='C:\\\\Users\\\\MeMyself\\\\AppData\\\\Roaming\\\\Python\\\\Python312\\\\site-packages\\\\certifi\\\\cacert.pem'\n",
      "2024-04-18 15:44:27,629 - DEBUG - connect_tcp.started host='api.gradio.app' port=443 local_address=None timeout=3 socket_options=None\n",
      "2024-04-18 15:44:27,785 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2024-04-18 15:44:27,787 - DEBUG - load_verify_locations cafile='C:\\\\Users\\\\MeMyself\\\\AppData\\\\Roaming\\\\Python\\\\Python312\\\\site-packages\\\\certifi\\\\cacert.pem'\n",
      "2024-04-18 15:44:27,828 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000271D3270740>\n",
      "2024-04-18 15:44:27,829 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000271D368E6D0> server_hostname='api.gradio.app' timeout=3\n",
      "2024-04-18 15:44:28,177 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000271D3920500>\n",
      "2024-04-18 15:44:28,178 - DEBUG - send_request_headers.started request=<Request [b'GET']>\n",
      "2024-04-18 15:44:28,179 - DEBUG - send_request_headers.complete\n",
      "2024-04-18 15:44:28,180 - DEBUG - send_request_body.started request=<Request [b'GET']>\n",
      "2024-04-18 15:44:28,180 - DEBUG - send_request_body.complete\n",
      "2024-04-18 15:44:28,181 - DEBUG - receive_response_headers.started request=<Request [b'GET']>\n",
      "2024-04-18 15:44:28,263 - DEBUG - Importing BlpImagePlugin\n",
      "2024-04-18 15:44:28,266 - DEBUG - Importing BmpImagePlugin\n",
      "2024-04-18 15:44:28,269 - DEBUG - Importing BufrStubImagePlugin\n",
      "2024-04-18 15:44:28,271 - DEBUG - Importing CurImagePlugin\n",
      "2024-04-18 15:44:28,272 - DEBUG - Importing DcxImagePlugin\n",
      "2024-04-18 15:44:28,274 - DEBUG - Importing DdsImagePlugin\n",
      "2024-04-18 15:44:28,283 - DEBUG - Importing EpsImagePlugin\n",
      "2024-04-18 15:44:28,285 - DEBUG - Importing FitsImagePlugin\n",
      "2024-04-18 15:44:28,289 - DEBUG - Importing FliImagePlugin\n",
      "2024-04-18 15:44:28,290 - DEBUG - Importing FpxImagePlugin\n",
      "2024-04-18 15:44:28,293 - DEBUG - Image: failed to import FpxImagePlugin: No module named 'olefile'\n",
      "2024-04-18 15:44:28,294 - DEBUG - Importing FtexImagePlugin\n",
      "2024-04-18 15:44:28,295 - DEBUG - Importing GbrImagePlugin\n",
      "2024-04-18 15:44:28,297 - DEBUG - Importing GifImagePlugin\n",
      "2024-04-18 15:44:28,303 - DEBUG - Importing GribStubImagePlugin\n",
      "2024-04-18 15:44:28,306 - DEBUG - Importing Hdf5StubImagePlugin\n",
      "2024-04-18 15:44:28,307 - DEBUG - Importing IcnsImagePlugin\n",
      "2024-04-18 15:44:28,315 - DEBUG - Importing IcoImagePlugin\n",
      "2024-04-18 15:44:28,317 - DEBUG - Importing ImImagePlugin\n",
      "2024-04-18 15:44:28,319 - DEBUG - Importing ImtImagePlugin\n",
      "2024-04-18 15:44:28,321 - DEBUG - Importing IptcImagePlugin\n",
      "2024-04-18 15:44:28,324 - DEBUG - Importing JpegImagePlugin\n",
      "2024-04-18 15:44:28,328 - DEBUG - Importing Jpeg2KImagePlugin\n",
      "2024-04-18 15:44:28,328 - DEBUG - Importing McIdasImagePlugin\n",
      "2024-04-18 15:44:28,330 - DEBUG - Importing MicImagePlugin\n",
      "2024-04-18 15:44:28,332 - DEBUG - Image: failed to import MicImagePlugin: No module named 'olefile'\n",
      "2024-04-18 15:44:28,333 - DEBUG - Importing MpegImagePlugin\n",
      "2024-04-18 15:44:28,334 - DEBUG - Importing MpoImagePlugin\n",
      "2024-04-18 15:44:28,342 - DEBUG - Importing MspImagePlugin\n",
      "2024-04-18 15:44:28,344 - DEBUG - Importing PalmImagePlugin\n",
      "2024-04-18 15:44:28,348 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 18 Apr 2024 13:44:28 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'3'), (b'Connection', b'keep-alive'), (b'Server', b'nginx/1.18.0'), (b'Access-Control-Allow-Origin', b'*')])\n",
      "2024-04-18 15:44:28,351 - DEBUG - Importing PcdImagePlugin\n",
      "2024-04-18 15:44:28,356 - INFO - HTTP Request: GET https://api.gradio.app/gradio-messaging/en \"HTTP/1.1 200 OK\"\n",
      "2024-04-18 15:44:28,358 - DEBUG - receive_response_body.started request=<Request [b'GET']>\n",
      "2024-04-18 15:44:28,359 - DEBUG - receive_response_body.complete\n",
      "2024-04-18 15:44:28,360 - DEBUG - response_closed.started\n",
      "2024-04-18 15:44:28,361 - DEBUG - Importing PcxImagePlugin\n",
      "2024-04-18 15:44:28,361 - DEBUG - response_closed.complete\n",
      "2024-04-18 15:44:28,362 - DEBUG - Importing PdfImagePlugin\n",
      "2024-04-18 15:44:28,362 - DEBUG - close.started\n",
      "2024-04-18 15:44:28,364 - DEBUG - close.complete\n",
      "2024-04-18 15:44:28,378 - DEBUG - Importing PixarImagePlugin\n",
      "2024-04-18 15:44:28,380 - DEBUG - Importing PngImagePlugin\n",
      "2024-04-18 15:44:28,380 - DEBUG - Importing PpmImagePlugin\n",
      "2024-04-18 15:44:28,383 - DEBUG - Importing PsdImagePlugin\n",
      "2024-04-18 15:44:28,384 - DEBUG - Importing QoiImagePlugin\n",
      "2024-04-18 15:44:28,388 - DEBUG - Importing SgiImagePlugin\n",
      "2024-04-18 15:44:28,390 - DEBUG - Importing SpiderImagePlugin\n",
      "2024-04-18 15:44:28,392 - DEBUG - Importing SunImagePlugin\n",
      "2024-04-18 15:44:28,394 - DEBUG - Importing TgaImagePlugin\n",
      "2024-04-18 15:44:28,395 - DEBUG - Importing TiffImagePlugin\n",
      "2024-04-18 15:44:28,396 - DEBUG - Importing WebPImagePlugin\n",
      "2024-04-18 15:44:28,401 - DEBUG - Importing WmfImagePlugin\n",
      "2024-04-18 15:44:28,404 - DEBUG - Importing XbmImagePlugin\n",
      "2024-04-18 15:44:28,406 - DEBUG - Importing XpmImagePlugin\n",
      "2024-04-18 15:44:28,408 - DEBUG - Importing XVThumbImagePlugin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an error importing the modules: No module named 'vectara_cli.span_marker'\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Function to handle package installations\n",
    "def install(packages):\n",
    "    for package in packages.split():\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "\n",
    "# Installing all required dependencies as per the project requirements\n",
    "install(\n",
    "    'spacy ipywidgets vectara-cli vectara-cli[span_marker] llama-index-core ' \\\n",
    "    'llama-index-readers-file llama-index-llms-together' \\\n",
    "    # 'llama-index-readers-file-epub llama-index-readers-file-flat llama-index-readers-file-html ' \\\n",
    "    # 'llama-index-readers-file-image llama-index-readers-file-image-caption ' \\\n",
    "    # 'llama-index-readers-file-image-deplot llama-index-readers-file-image-vision-llm ' \\\n",
    "    # 'llama-index-readers-file-ipynb llama-index-readers-file-markdown llama-index-readers-file-mbo ' \\\n",
    "    # 'llama-index-readers-file-paged_csv llama-index-readers-file-pymu_pdf ' \\\n",
    "    # 'llama-index-readers-file-slides llama-index-readers-file-tabular ' \\\n",
    "    # 'llama-index-readers-file-unstructured llama-index-readers-file-xml llama-index-readers-file-rtf ' \\\n",
    "    ' python-magic-bin==0.4.14 gradio'\n",
    ")\n",
    "\n",
    "# Importing libraries after installation to check if all are correctly installed\n",
    "try:\n",
    "    import spacy, ipywidgets, vectara_cli, llama_index, gradio\n",
    "    from vectara_cli.core import VectaraClient\n",
    "    from vectara_cli.span_marker.noncommercial.nerdspan import Span\n",
    "    from vectara_cli.span_marker.commercial.enterprise import EnterpriseSpan\n",
    "    # from llama_index import core as llama_index_core, readers, llms\n",
    "    print('All modules have been successfully imported and are ready for use.')\n",
    "except Exception as e:\n",
    "    print('There was an error importing the modules:', str(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Data Loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 15:44:53,590 - DEBUG - Starting new HTTPS connection (1): raw.githubusercontent.com:443\n",
      "2024-04-18 15:44:54,027 - DEBUG - https://raw.githubusercontent.com:443 \"GET /TeamTonic/Vectonic/devbranch/src/dataloader.py?token=GHSAT0AAAAAACKMIGKSE4A5FEDT6UYXGCC6ZRBFM6A HTTP/1.1\" 200 2146\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_index.readers.web'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m     file\u001b[38;5;241m.\u001b[39mwrite(content)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# After saving it locally, import the necessary classes\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataProcessor, DocumentLoader\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Initialize and use the classes\u001b[39;00m\n\u001b[0;32m     17\u001b[0m data_processor \u001b[38;5;241m=\u001b[39m DataProcessor()\n",
      "File \u001b[1;32mc:\\Users\\MeMyself\\Vectonic\\eval\\dataloader.py:29\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageVisionLLMReader \u001b[38;5;66;03m# https://github.com/run-llama/llama_index/blob/main/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/image_vision_llm/base.py\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# from llama_index.readers.file import SimpleDirectoryReader\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# from llama_index.core.node_parser import SentenceSplitter\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mweb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AsyncWebPageReader\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mllama_parse\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_parse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LlamaParse\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'llama_index.readers.web'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Correct URL to the raw content of the Python file on GitHub\n",
    "url = 'https://raw.githubusercontent.com/TeamTonic/Vectonic/devbranch/src/dataloader.py?token=GHSAT0AAAAAACKMIGKSE4A5FEDT6UYXGCC6ZRBFM6A'\n",
    "\n",
    "# Make a GET request to fetch the raw content of the Python file\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    content = response.text\n",
    "    # Save the Python code to a local file\n",
    "    with open('dataloader.py', 'w') as file:\n",
    "        file.write(content)\n",
    "    # After saving it locally, import the necessary classes\n",
    "    from dataloader import DataProcessor, DocumentLoader\n",
    "\n",
    "    # Initialize and use the classes\n",
    "    data_processor = DataProcessor()\n",
    "    document_loader = DocumentLoader()\n",
    "    print(\"Classes DataProcessor and DocumentLoader have been successfully imported and are ready for use.\")\n",
    "else:\n",
    "    raise Exception(f\"Failed to download the file: status code {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_index.readers.web'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataProcessor , DocumentLoader\n\u001b[0;32m      2\u001b[0m data_processor \u001b[38;5;241m=\u001b[39m DataProcessor()\n\u001b[0;32m      3\u001b[0m document_loader \u001b[38;5;241m=\u001b[39m DocumentLoader()\n",
      "File \u001b[1;32mc:\\Users\\MeMyself\\Vectonic\\eval\\dataloader.py:29\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageVisionLLMReader \u001b[38;5;66;03m# https://github.com/run-llama/llama_index/blob/main/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/image_vision_llm/base.py\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# from llama_index.readers.file import SimpleDirectoryReader\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# from llama_index.core.node_parser import SentenceSplitter\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mweb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AsyncWebPageReader\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mllama_parse\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_parse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LlamaParse\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'llama_index.readers.web'"
     ]
    }
   ],
   "source": [
    "from dataloader import DataProcessor , DocumentLoader\n",
    "data_processor = DataProcessor()\n",
    "document_loader = DocumentLoader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Make a Simple RAG Pipeline using the enhanced and non enhanced texts !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vectara",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
